\subsection{Knowledge Extraction} % (fold)
\label{sub:knowledge}
In this section we are going to compile an overview of some knowledge which we have extracted from the data. 


While testing various features we found various weights which seem to be very indicative of the outcome of the match. In this section we will list some of them. It is useful to list these, because they imply a good strategy in the game.

Firstly, one should know that no weights were much higher than others, which would imply the game is relatively balanced! If the opposite was the case, certain strategies would be too good. Which probably would result in a rebalance of the game. Also note that the weights of our model are mostly symmetric around 0, which implies that the game is somewhat symmetric across the two teams. It is also important to realise the weights are based on the matches in our dataset, and the symmetric match might not have been played. We are now going to list some important features. 

Note that the sign implies which team the feature is good for. Since we are predicting if blue team wins, negative features are bad for the blue team. The most notable counter pair features:
\begin{itemize}
    \item Jinx-BLUE-VS-LeSin-PURPLE (-)
    \item Blitzcrank-BLUE-VS-LeSin-PURPLE (-)
    \item LeSin-BLUE-VS-Blitzcrank-PURPLE (+)
\end{itemize}
This means that the champion Jinx is bad vs LeSin, to explain this one can look at their abilities. Jinx is a very squishy, but high damage dealing champion, while LeSin can teleport close to enemies and deal high damage. Blitzcrank vs LeSin and Nidalee, might be bad for Blitzcrank because he can pull enemies close to him and deal damage, but LeSin can quickly jump away from Blitzcrank.

Single champions 
\begin{itemize}
    \item Bard-PURPLE (-)
    \item Sejuani-PURPLE(-)
    \item Blitzcrank-BLUE (+)
    \item Azir-PURPLE (+)
\end{itemize}

Most of these features directly correlate to the average winrate of each champion. In this case Bard, Sejuani and Blitzcrank have the highest winrates individually while Azir has the lowest winrate.

We also defined the feature vector \Cref{eq:best-rank}, this is by far the best feature. That is, the team with the highest rank will often be the winner.


\textcolor{red}{ADD MORE WHEN TESTS ARE DONE, MAYBE REMOVE SOME}



\subsubsection{Low accuracy}

So why are we not able to able to achieve a higher accuracy? There are two options why this is the case: 1 we have not used thoroughly representing features or 2 the maximally achievable accuracy is close to ours and it simply is not possible to get a better accuracy. There is not much we can do about the first point, but we definitely have tested with a lot of different features. But then, why is it the case that we can not achieve higher accuracy? It is quite clear that the intention of the game maker is to balance the game, such that no champion or combination of champions is too overpowered. If one champion becomes too strong it will be changed and reduced in power. If we look at the newest version of the game the champions which we have selected as strong and weak have been rescaled in power. It is definitely the case that picking certain champions or even counterpicking the enemy, will make winning the game easier, but skill is also insanely

\todo{need more text here}



