\FloatBarrier
\subsection{Motivation}\label{sec:motivation}
As seen in \Cref{sec:mlandonlinevideogames}, a lot of work has been done using machine learning for video games, however LoL is a rather unexplored game. 
In this paper, we will attempt to develop a method for LoL, which will help players pick champions that give their team the greatest probability of winning. In \Cref{sec:onlinevideogames}, LoL is described and it is clear that the number of decisions each player can make is large. Due to this large number of decisions each player can make, a large quantity of match data is required to get a proper representation. 

The data is provided by Riot Games who, through their public API, grants access to an enormous amount of data, including match data.
The large quantity of data means that we will have a \emph{big data problem}, which means the traditional data processing methods can not effectively be applied. Storage of big data and finding a machine learning method that scales with large data are some of the things that will be explored in this paper.

%===old===
%The focus of this paper will be to develop a method for LoL, that helps players make strategically good decisions about which champions to select. 
%This will be done using knowledge of the opposing teams chosen champions. 
%This will result in a suggestion for a team that has the highest probability of winning. 
%These decisions will be based on a model learned using a large quantity of data from previously played matches. 
%Before the game starts, one can input data about the two teams into the model, %and as output gets an estimated probability of each of team being the winner.

%Riot Games provides an enormous amount of data from played matches, which can be accessed for free using the Riot Games API.\@
%The sheer volume of this data means that traditional data processing methods can not effectively be applied, and that we have a \emph{big data problem}. 
%======

\subsubsection{Big Data Problem}\label{sec:big_data_problem}
A big data problem is characterised by the three factors: \emph{volume}, \emph{velocity}, and \emph{variety}. As we have gained access to more than 400GB of match data, we have a great volume of data. The variety of the data is on the other hand low as it is on the same format and it is all from the same source. Velocity is not an issue either, as the data we are going to work with is a static dataset. It could however be expanded to a velocity problem as well, because patches that alter the game are occasionally applied to the game. Patches can change how champions work or even add new ones. The model could then continuously be updated for every new patch, making velocity an issue to consider. Riot Games generates 40GB of new match data per day in Western Europe alone. We are not going to consider this issue and merely focus on finding out, to which extend the outcome of a match can be predicted on a single patch. Therefore, our only big data concern is related to volume~\cite{madden2012databases}.

\todo{det er lort det der kommer her}
A high volume of data poses a number of problem on a single computer. Let us consider these problems: One problem may be that the data is too big to be stored. This can be solved by buying additional storage units. Secondly, we are limited in processing power, adding more computational power is not economical and may introduce bottleneck issues. A way to solve these issues is to split and distribute the data across multiple machines, which means having several units for processing with their own storage. By assigning every machine to process the data stored at its own storage the computation time can be decreased.
%A single node is chosen as the \textit{master}, which schedules tasks at the other nodes called \textit{slaves}. A such setup is called a \textit{cluster}, and is greatly scaleable for a wide range of applications, namely those applications that can be parallelized.
This means that certain machine learning algorithms are more applicable, since the problem will have to be split up and computed in parallel. 


