\subsection{Motivation}\label{sec:motivation}

\subsubsection{Problem to Solve} % (fold)
\label{sec:problem_to_solve}
As seen in \Cref{sec:mlandonlinevideogames}, a lot of work has been done on machine learning for other video games. LoL is however a rather unexplored game, which is the game this paper will focus on. We wish to help players make strategically good decisions about which champions to select at the beginning of the game.
These decisions will be based on a model learned using a large quantity of data from previously played matches. Before the game starts, one can input data about the two teams into the model, and as output get en estimated probability of each of team being the winner.
Riot Games provides an enormous amount of data from previous matches, which can be accessed for free using the Riot Games API.
The sheer volume of this data means that traditional data processing methods can not effectively be applied - we have a \emph{big data problem}. 


\subsubsection{Big Data Problem} % (fold)
\label{sec:big_data_problem}

A big data problem is characterized by at least one of the 3 factors, volume, velocity, and variety. We have downloaded more than 400GB of data using the Riot Games API, so we definitely have a great volume of data. The variety of data is low as we get it all from the same source and in the same format (JSON). Since patches that alter the game play are regularly released for LoL, one may want to keep the model up to date by training on new data as soon as it arrives. As new match data arrives continuously at a rate of 40GB per day (in Western Europe), one may see that as a high velocity problem. We will however look away from real time data and merely focus on finding out, to which extend the outcome of a match can be predicted. Therefore, our only big data concern is related to volume~\cite{madden2012databases}.

A high volume of data poses a number of problem on a standalone system. One problem may be that the data is too big be stored on a single system.
This can of course be solved by buying additional storage units. But that does not solve another problem, that the number of CPU's are limited on a single system, and depending on the application, either calculations or transfer of data may be a bottleneck.
By having several processing units (called nodes), that each have their own storage, the data can be split and distributed across multiple nodes. By assigning every node to process the data stored at its own storage, the slow movement of data between nodes can be reduced.
A single node is chosen as the \textit{master}, which schedules tasks at the other nodes called \textit{slaves}. A such setup is called a \textit{cluster}, and is greatly scaleable for a wide range of applications, namely those applications that can be parallelized.
This means that certain machine learning algorithms are more applicable, since the problem will have to be split up and computed in parallel. We will briefly look at one technique for solving big data problems in the next section.

\subsubsection{MapReduce} % (fold)
\label{sec:mapreduce_programming_model}
MapReduce is a programming model which is especially used in the context of ``Big Data''. The model is useful in the context of processing large amounts of data, utilizing parallelization. The main reason for the success of the MapReduce model, is mostly because it is easy for the programmer to parallelize, and its low-cost, high-compute property. MapReduce is well-suited in a distributed computing setting, handling data large enough to not fit into a single disk.
MapReduce is comprised of a \emph{map} procedure and a \emph{reduce} procedure. The two procedures are split into the following actions:

\begin{description}
    \item[Map] This procedure takes as input a key-value pair and ``sets-up'' the data, by e.g.\ filtering or sorting. The resulting output is an intermediate key-value pair used for input to the reduce function.
    \item[Reduce] This procedure takes an intermediate key and a set of values for that key, it then reduces by merging these values into a result
\end{description}
%src: http://static.googleusercontent.com/media/research.google.com/da//archive/mapreduce-osdi04.pdf









%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
