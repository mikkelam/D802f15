\subsection{Motivation}\label{sec:motivation}
As seen in \Cref{sec:mlandonlinevideogames} some work has been done using machine learning for video games, however LoL is a rather unexplored game. 
In this paper we will attempt to develop a method for LoL, by using machine learning and big data techniques, which will help players and game developers analyse the game, and make better choices. In \Cref{sec:intro} the central parts of LoL is described, where we show that LoL is a complex game, as the number of choices each player can make is very large. Due to the high complexity, the use of big data techniques and a large quantity of match data, has the potential to increase the predictive power of machine learning techniques. Riot exposes metadata of matches played through a public developer API. To thoroughly investigate the large statespace of LoL we are going to work with millions of matches. This makes the problem harder to solve, because it is not possible to manage effectively through traditional data processing methods.

\subsubsection{Big Data Problem}\label{sec:big_data_problem}
A big data problem is characterised by the three factors: \emph{volume}, \emph{velocity}, and \emph{variety}. These factors are ever changing as a result of technology improvements. For instance a data volume in the gigabyte range was once impossible for a single machine to manage, whereas modern hardware is more than capable. Big data is a somewhat vague term used to describe a system where one of these factors challenge traditional data processing methods. As we have extracted around 456GB of match data, we have a great volume of data. The variety of the data is on the other hand low as it is on the same format and it is all from the same source. Velocity is not an issue either, as the data we work with is a static dataset. It could become a velocity problem, due to the fact that patches that alter the game are occasionally applied to the game. Patches change the game, e.g. a champion can be made weaker. This means that the classifier will need to be updated, making velocity an issue to consider. Combine this with the fact, that 40GB of data is stored per day in Western Europe alone, based on the dataset we use. We are however not going to consider this issue and merely focus on predicting outcomes of matches. Therefore our only big data concern is related to volume~\cite{madden2012databases}.

A high volume of data can cause a number of problems when using a single computer. The data can simply be too large to store on a single machine unless a lot of storage units have been attached. Using many storage units on a single computer is not fault tolerant, because if one unit dies its data is lost. Another issue is the processing power, additional computational power could introduce bottleneck issues. These issues can be solved by using a group of machines with a distributed file system. By having the data distributed, several copies can be maintained so the data is not lost if a single machine or storage unit crashes. In addition, using multiple machines adds computational power without adding a data transfer bottleneck issues, since each machine can do computation on its local data.
%This also means that certain machine learning algorithms are more applicable, since the problem will have to be split up and computed in parallel. 

\subsection{Overview}\label{sec:overview}
In \Cref{sec:prelim} we present preliminary knowledge about supervised learning and the the distributed systems which we will utilise. In \Cref{sec:features} we introduce the data set used in this paper, followed by selection and transformation of features. In \Cref{sec:cluster} we present the cluster which we use, including some tests about its performance and scalability. The results of all the experiments will be presented in \Cref{sec:testing}, where both initial experiments performed on a single computer and experiments on the cluster will be present. After the results have been presented, we discuss the knowledge extracted from the experiments. Finally in \Cref{sec:conclusion} the conclusion of the project will be presented along with suggestions for future work that can be explored.