\section{Preliminaries}\label{sec:prelim}
In this section, theory and knowledge that is imperative for the understanding of this paper will be presented. In \Cref{sec:supervisedclassification}, several supervised learning concepts will be explained as it is the primary method used in this paper. In \Cref{sec:distributed}, the distributed file system Hadoop and the large scale data processing engine Apache Spark is introduced, as well as the motivation for using those tools in this project.

\subsection{Supervised Classification with Big Data}\label{sec:supervisedclassification}
In this section several supervised classifications methods will be explored, including information on how they handle big data. 
% The problem of supervised classification bla bla bla...
% when dealing with a large amount of labelled data ect.

% write motivation for using supervised learning (DATA!!!) 
%In this section, theory or knowledge that is imperative for the understanding of this paper will be presented. In \Cref{sec:supervised learning}, several supervised learning concepts will be explained as it is the primary method used in this paper. In \Cref{sec:distributed}, \emph{Hadoop distributed filesystem} (HDFS) is briefly outlined followed by an introduction to Apache spark which is the cluster computing system mainly used throughout this paper.

\subsubsection{Supervised learning}
Supervised learning is the process of learning the parameters of a prediction model using a corpus of labelled data.
In supervised learning the data consists of objects with labels of the form 
$(\mathbf{x}_1,y_1),(\mathbf{x}_2,y_2), \dots, (\mathbf{x}_N,y_N)$.
Where $\textbf{x}$ is a vector of inputs and $y$ is the class label for the data point.
The goal of supervised learning is to produce a model that is able to predict a label from the inputs alone.
When the domain of the label is continuous this is called a regression model and if it is discrete it is called a classification model.

\paragraph{Feature Representation}\label{sec:phi}
It is possible to design a lot of features for the model by combining and transforming the original inputs.
\begin{align*}
x &\rightarrow \phi(x) \\
&\rightarrow (\phi_1(x), \phi_2(x), \phi_3(x), \phi_4(x)) \\
&\rightarrow (1, x_1, x_1^2, x_1x_2)
\end{align*} 
Above we have a few examples of how an input vector $x$ can be transformed.
The examples include a constant, the identity, a polynomial and the combination of two inputs.

\subsubsection{Linear Models}
% insert image showing a line and some data points.

When attempting to predict a continuous value, one standard method is by using linear regression.
%A very popular model for classification is the linear classification model.
The linear regression model predicts the value of $y$ with $\hat{y}$. $\hat{y}$ is found with the hypothesis function $h(x)$ by assigning weights $(\mathbf{w}_1\phi_1),(\mathbf{w}_2\phi_2), \dots (\mathbf{w}_M\phi_M)$ to the features and computing their sum.
\[h_w(x) = \hat{y} = w_0 + \sum_{i=1}^M w_i \phi_i(x) \]

Where $w_0$ is a special case called the intercept, however to avoid having this special case we add  $w_0$ to the feature $\phi_0(x)=1$, which allows us to use the intercept as a normal feature. 
The next question becomes, how do we assign a value to the weights?
Given the amount of data we have available, it would be preferable to learn these weights from the data. 

\paragraph{Linear Regression}
Since the goal is to fit the hypothesis function to a training set, linear regression uses the following loss function given the data $D$ and the weights $w$.

\[ L_D(w) = \sum_{n=1}^N (y_n-\hat{y}_n)^2 = \sum_{n=1}^N (y_n - \sum_{w_i \in w} w_i \phi_i(x_n))^2 \] 
The best parameters are those that minimize the loss function. Since the function is convex, the best parameters can be found either analytically by setting the derivative to 0, or by using an iterative method introduced later called gradient descent.

When giving a prediction $\hat{y}$ on the value of a discrete binary label we use a thresholding function:
\[
\hat{y} = 
\begin{cases}
  1 &\text{ if } h_w(x) > \tau \\
  0 &\text{ if } h_w(x) \leq \tau  % should this be 0 < f(x) \leq 0 ????
\end{cases}
\] 
Although this may work in some cases, a dataset with a few outliers can significantly skew the decision boundary.
%insert image of a skewed decision boundary.
In order to combat this problem we introduce a new linear model for classification called logistic regression.

\paragraph{Logistic Regression}\label{sec:logistic}

In logistic regression we use the so called logistic or sigmoid function to squash the prediction into the interval $[0,1]$.
\[ \hat{y} = \sigma(h_w(x)) = \frac{1}{1+e^{-h_w(x)}} \]
By doing this a single outlying data point is no longer able to skew the decision boundary of the hypothesis function.
However this comes at a cost.
When combining the sigmoid and squared sums loss function, the resulting loss function is no longer convex, which means that we may only find a local minimum when searching for the best parameters.
Logistic regression solves this problem by introducing an error function:
\[E_w(y,h_w(x)) = \begin{cases}
	-ln(\sigma(h_w(x))) &\text{if y = 1}\\	
	-ln(1-\sigma(h_w(x))) &\text{if y = 0}
%	-ln(\sum_{w_i \in w} w_i \phi_i(x_n)) &\text{if y = 1}\\	
%	-ln(1-\sum_{w_i \in w} w_i \phi_i(x_n)) &\text{if y = 0}
\end{cases}\]
When the error of the hypothesis function is 0, the error function returns 0 as well. When the error of the hypothesis function goes towards 1, the penalty caused by the error function goes towards infinity.
When using the error function to define the loss function
$$L_D(w) = \sum_{n=1}^N E_w(y_n, h_w(x_n))$$
the loss function becomes convex again.

\subsubsection{Overfitting and Underfitting}
% overfitting vs. underfitting
Learning the parameters of a linear model can sometimes result in a model that is too simple or too complex.
In the case of a model that is too simple, it is unable to catch the nuances presented in the data.
% insert image with a model that is too simple.  
When a model is too complex or the data used in training has a bias compare to the real world examples.
This can result in overfitting.
Overfitting means that the model is too closely fitted to the training data, where it will provide good results on the training data but do increasingly poor on new and unseen data.
% insert image of a model that overfits the data. 

\paragraph{Dealing with Overfitting}
% dividing data into test, training and validation sets.
% cross validation

One way of avoiding overfitting is by using a technique called cross validation. \todo{der skal vÃ¦re mere end 1 training set til cross validation}
With cross validation the data is divided into two separate sets, where one is used for training and the other to test for overfitting. 
This way it becomes possible to detect when the model starts to overfit the training data.
A typical way to do this is by using a 70-30 split thereby using 70\% for training and 30\% for testing.
If the dataset is small, 30\% may be too much of a sacrifice.

% K-Fold cross validation
Another possibility is to use k-fold cross validation.
When applying this method the dataset is partitioned into $k$ numbers of ``folds'', with 1 test fold and $k-1$ training folds.
The model is then trained for $k$ iterations, such that each iteration use a different fold.
Thereby it becomes possible to use all of the data as both training and test set.
% Source: AI pool, macworth, p. 324

\subsubsection{Regularisation}

To combat the problem of overfitting, we can also use a method called regularisation.
In regularisation we penalise large weights, by adding a second term to the loss function.
Generally speaking there exist two types of regularisation L1 and L2.
L1-regularisation is good at encouraging sparse solutions when there are many irrelevant features whereas L2-regularisation is better when most features are relevant.

\begin{itemize}
\item L1-Regularisation: $L_w = \lambda \sum_{m} \vert w_m \vert $ \\
\item L2-Regularisation: $L_w = \frac{\lambda}{2} \sum_{m} {w_m}^2$
\end{itemize}

Where the regularisation constant $\lambda$ scales the regularisation penalty in relation to the data. For Logistic regression with L2-Regularisation the combined loss function looks like this.

\[ L(\mathbf{w})
  = L_D(w) + L_w 
  = \sum_{n=1}^N E_w(y_n, h_w(x_n)) + \frac{\lambda}{2} \sum_{m=1}^{M} {w_m}^2 \] 

\subsubsection{Batch Gradient Descent}\label{sec:batch}

Since we have a large number of features, applying an analytic solution to find the weights quickly becomes impractical.
Therefore we need to use an iterative approach.
One such method is called batch gradient descent.

In batch gradient descent we iteratively update the weights $w_j$ for $0 \leq j \leq M$, by a value proportional to the partial derivative of the loss function until the value converges, i.e.\ when $w_{j}^{(i)} = w_j^{(i+1)}$ for all weights.

%\[ w_j \leftarrow w_j - \eta \frac{\partial L(\textbf{w})}{ \partial w_j} 
%	= w_j - \eta \frac{\partial \sum_{n=1}^N E_w(y_n, h_w(x_n))}{ \partial w_j}  \]

\[ w_j^{(i)} = w_j^{(i-1)} - \eta \frac{\partial L(\textbf{w})}{\partial w_j^{(i-1)}}
       = w_{j}^{(i-1)} - \eta \frac{\partial \sum_{n=1}^N E_w(y_n, h_w(x_n)) + \frac{\lambda}{2}\sum_{m=1}^M w_m^2}{\partial w_j^{(i-1)}} \]  

The value $\eta$ represent the learning rate i.e.\ how big a step the algorithm should take in each iteration.
This value need to be chosen wisely as a value that is too small will increase the number of iterations required and a value that is too large could cause the algorithm to diverge.

When dealing with a large dataset this method runs into a problem, namely that computing the partial derivative requires summing over all of the data points in the training set in every iteration. 

\subsubsection{Stochastic Gradient Descent}\label{sec:stochastic}

Stochastic gradient descent solves the problem of large dataset by updating the weights on each data point.
This also makes the algorithm a good choice for updating a model online with continuously incoming data. 

In the algorithm for stochastic gradient descent we first randomly shuffle all objects in the dataset $D$.
We then iteratively update the weights in a way similar to batch gradient descent but using this equation.

$$ w_j^{(i)} = w_j^{(i-1)} - \eta \frac{\partial E_w(y_n, h_w(x_n))}{\partial w_j^{(i-1)}} $$

For each object $(x_n, y_n)$ in the dataset.

One problem with stochastic gradient descent is that the algorithm never converges, but instead moves the weight around in an area close to the minimum value.
Therefore it becomes necessary to use a separate strategy to accomplish this.
Among these strategies are:
\begin{itemize}
\item Adding a final iteration that uses batch gradient descent 
\item Have a final phase that takes the average of last 10 iterations 
\item Comparing change in weights with a threshold value
\end{itemize}

The pseudocode for the algorithm can be seen in \Cref{lst:sgt}.

\begin{listing}[H]
\begin{minted}{python}
def StochasticGradientDescent(W,E,D):
  Shuffle(D)

  Repeat Until hasConverged(W,oldW):
    for x in D do:
      for w in W do: 
        w := w - eta * partial(E(W,x),w)
\end{minted}
\caption{Stochastic Gradient Descent}
\label{lst:sgt}
\end{listing}

\paragraph{Mini-Batch Gradient Descent}\label{sec:mini-batch}

Because stochastic gradient descent updates the weights using individual data points.
The value has a tendency to jump around a lot instead of moving directly down the gradient towards the minimum.
To alleviate this problem there exist a variant of stochastic gradient descent called mini-batch gradient descent. 
The only difference between them being that each update is an average of ten updates in mini-batch gradient descent. 







%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
