\subsection{Spark's implementation of logistic regression}\label{sec:sparklogreg}
The purpose of this section is to inspect how logistic regression is implemented in Spark.
The first bit of code inspected is 
\begin{listing}[H]
\begin{minted}[linenos, firstnumber=219]{python}
class LogisticRegressionWithSGD(object):

    @classmethod
    def train(cls, data, iterations=100, step=1.0, miniBatchFraction=1.0,
              initialWeights=None, regParam=0.01, regType="l2", intercept=False,
              validateData=True):  
\end{minted}
\caption{Lines from classification.py}
\end{listing}

The models available in Spark's MLlib are all implemented in scala, all the models are made available in Pyspark through the PythonMLLibAPI module. 
The main scripts involved with logistic regression in spark are. 
\begin{itemize}
\item LogisticRegression.scala
\item GradientDescent.scala
\item Updater.scala 
\item Gradient.scala
\end{itemize}
In LogisticRegression.scala a LogisticGradient and SquaredL2Updater is created and passed to GradientDescent which returns the weights needed to create the model. 

\begin{listing}[H]
\begin{minted}[linenos, firstnumber=211]{scala}
private val gradient = new LogisticGradient()
private val updater = new SquaredL2Updater()
override val optimizer = new GradientDescent(gradient, updater)
        .setStepSize(stepSize)
        .setNumIterations(numIterations)
        .setRegParam(regParam)
        .setMiniBatchFraction(miniBatchFraction)
\end{minted}
\caption{Lines from LogisticRegression.scala}
\label{lst:gd_logreg}
\end{listing}

The main function involved with calculating the weights is runMiniBatchSGD from line 149 in GradientDescent.scala. The following line of scale code shows how the weights are calculated. 
\begin{listing}[H]
\begin{minted}[linenos, firstnumber=181]{scala}
var regVal = updater.compute(
      weights, Vectors.dense(new Array[Double](weights.size)), 0, 1, regParam)._2
for (i <- 1 to numIterations) {
  val bcWeights = data.context.broadcast(weights)
  // Sample a subset (fraction miniBatchFraction) of the total data
  // compute and sum up the subgradients on this subset (this is one map-reduce)
  val (gradientSum, lossSum, miniBatchSize) = data.sample(false, miniBatchFraction, 
      42 + i).treeAggregate((BDV.zeros[Double](n), 0.0, 0L))(
      seqOp = (c, v) => {
        // c: (grad, loss, count), v: (label, features)
        val l = gradient.compute(v._2, v._1, bcWeights.value, Vectors.fromBreeze(c._1))
        (c._1, c._2 + l, c._3 + 1)
      },
      combOp = (c1, c2) => {
        // c: (grad, loss, count)
        (c1._1 += c2._1, c1._2 + c2._2, c1._3 + c2._3)
      })

    if (miniBatchSize > 0) {
      /**
       * NOTE(Xinghao): lossSum is computed using the weights from the previous iteration
       * and regVal is the regularization value computed in the previous iteration as well.
       */
      stochasticLossHistory.append(lossSum / miniBatchSize + regVal)
      val update = updater.compute(
        weights, Vectors.fromBreeze(gradientSum / miniBatchSize.toDouble), stepSize,
              i, regParam)
        weights = update._1
        regVal = update._2
\end{minted}
\caption{Lines from GradientDescent.scala}
\label{lst:runMiniBatchSGD}
\end{listing}
The lines 187 to 209 in side the for-loop is a map reduce resonsible for calculating loss accordingly to the weights, and then updating the weights to minimize loss with respect to regolization. Lines 191 and 192 use the LogisticGradient object created by the LogisticRegression object to compute loss besed on the  label, features current weights and gradient. On line 205 the updater computes new weights and a new regVal from the given weights, avage gradient, stepSize, iteration and regularization factor.  
To inspect how the loss is calculated the sniplet responsible for this calculation is indluded. 
\begin{listing}[H]
\begin{minted}[linenos, firstnumber=173]{scala}
val margin = -1.0 * dot(data, weights)
val multiplier = (1.0 / (1.0 + math.exp(margin))) - label
axpy(multiplier, data, cumGradient)
if (label > 0) {
  // The following is equivalent to log(1 + exp(margin)) but more numerically stable.
  MLUtils.log1pExp(margin)
} else {
  MLUtils.log1pExp(margin) - margin
} 
\end{minted}
\caption{Lines from Gradient.scala}
\label{lst:sparkloss}
\end{listing}
The default updater used for logistic regression is a SquaredL2Updater from Updater.scala
the code ran in the compute function is the following: 

\begin{listing}[H]
\begin{minted}[linenos, firstnumber=138]{scala}
override def compute(
  weightsOld: Vector,    
  gradient: Vector,  
  stepSize: Double,
  iter: Int,
  regParam: Double): (Vector, Double) = {
    // add up both updates from the gradient of the loss (= step) as well as
    // the gradient of the regularizer (= regParam * weightsOld)
    // w' = w - thisIterStepSize * (gradient + regParam * w)
    // w' = (1 - thisIterStepSize * regParam) * w - thisIterStepSize * gradient
    val thisIterStepSize = stepSize / math.sqrt(iter)
    val brzWeights: BV[Double] = weightsOld.toBreeze.toDenseVector
    brzWeights :*= (1.0 - thisIterStepSize * regParam)
    brzAxpy(-thisIterStepSize, gradient.toBreeze, brzWeights)
    val norm = brzNorm(brzWeights, 2.0)

    (Vectors.fromBreeze(brzWeights), 0.5 * regParam * norm * norm)
  }
\end{minted}
\caption{Lines from Updater.scala}
\label{lst:updatercal}
\end{listing}