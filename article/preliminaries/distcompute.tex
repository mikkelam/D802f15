\subsection{Computing Distributed Systems}\label{sec:distributed}
In this section we will introduce distributed systems, which we are going to use. These systems will help us distribute the data across multiple machines, as well as distributed parallel computations. 


\subsubsection{Hadoop Filesystem}\label{sec:hadoopfilesystem}
Hadoop filesystem (HDFS) is a distributed filesystem that seeks to increase fault tolerance on very large datasystems. The filesystem is designed to be distributed across inexpensive commodity hardware, where recovery is done quickly and automatically. HDFS is run on a cluster, where one machine exist as a \emph{master} which runs the \emph{namenode}, which is a central node that manages the location of file blocks and distributes assigned work. Blocks are used as a means to split large files, replicate and distribute them across the clusters \emph{data nodes}. Ensuring file coherency could become very complicated in such a system, which is why Hadoop implements a simple \emph{write once, read many} model. It is common that the files used with Hadoop is of the Gigabyte-Terabyte size.
As seen in \Cref{fig:hadoop}, the namenode can be seen as the root of a HDFS cluster. An application access data by first requesting the locations of a fileâ€™s blocks from the namenode and then use those locations to read directly from data nodes~\cite{hadoopIntro}. 

\begin{figure}[!htb]
  \centering
  \scalebox{0.75}{
    \begin{tikzpicture}[->,>=stealth',bend angle=45,auto]
      % Disks
      \node[cylinder,draw=black,thick,aspect=0.3,minimum height=1.3cm,minimum width=1cm,shape border rotate=90,cylinder uses custom fill,xshift=-5cm] (D1) {Disk};
      \node[cylinder,draw=black,thick,aspect=0.3,minimum height=1.3cm,minimum width=1cm,shape border rotate=90,cylinder uses custom fill,xshift=-2cm] (D2) {Disk};
      \node[cylinder,draw=black,thick,aspect=0.3,minimum height=1.3cm,minimum width=1cm,shape border rotate=90,cylinder uses custom fill,xshift=2cm] (D3) {Disk};
      \node[cylinder,draw=black,thick,aspect=0.3,minimum height=1.3cm,minimum width=1cm,shape border rotate=90,cylinder uses custom fill,xshift=5cm] (D4)  {Disk};
      \node[cylinder,draw=black,thick,aspect=0.3,minimum height=1.3cm,minimum width=1cm,shape border rotate=90,cylinder uses custom fill,xshift=5cm,yshift=5cm] (D5) {Disk};
      \node[cylinder,draw=black,thick,aspect=0.3,minimum height=1.3cm,minimum width=1cm,shape border rotate=90,cylinder uses custom fill,xshift=-5cm,yshift=5cm] (D6) {Disk};

      % Data nodes
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2cm, minimum height=2.5cm,xshift=-5cm,yshift=0.3cm,label={[yshift=-0.65cm]Data node}] (DN1) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2cm, minimum height=2.5cm,xshift=-2cm,yshift=0.3cm,label={[yshift=-0.65cm]Data node}] (DN2) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2cm, minimum height=2.5cm,xshift=2cm,yshift=0.3cm,label={[yshift=-0.65cm]Data node}] (DN3) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2cm, minimum height=2.5cm,xshift=5cm,yshift=0.3cm,label={[yshift=-0.65cm]Data node}] (DN4) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2cm, minimum height=2.5cm,xshift=-5cm,yshift=5.3cm,label={[yshift=-0.65cm]Data node}] (DN5) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2cm, minimum height=2.5cm,xshift=5cm,yshift=5.3cm,label={[yshift=-0.65cm]Data node}] (DN6) {};

      % Namenodes
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2cm, minimum height=2.5cm,xshift=-2cm,yshift=5.3cm,label={[yshift=-0.65cm]Namenode}] (NN1) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2cm, minimum height=2.5cm,xshift=2cm,yshift=5.3cm,label={[yshift=-0.65cm]Namenode}] (NN2) {};

      % Server
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2.5cm, minimum height=3.5cm,xshift=-5cm,yshift=0.6cm,label={[yshift=-0.65cm]Server}] (S1) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2.5cm, minimum height=3.5cm,xshift=-2cm,yshift=0.6cm,label={[yshift=-0.65cm,xshift=-0.5cm]Server}] (S2) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2.5cm, minimum height=3.5cm,xshift=5cm,yshift=0.6cm,label={[yshift=-0.65cm]Server}] (S3) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=2.5cm, minimum height=3.5cm,xshift=2cm,yshift=0.6cm,label={[yshift=-0.65cm,xshift=0.5cm]Server}] (S4) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=5.5cm, minimum height=3.5cm,xshift=-3.5cm,yshift=5.6cm,label={[yshift=-0.65cm]Server}] (S5) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=5.5cm, minimum height=3.5cm,xshift=3.5cm,yshift=5.6cm,label={[yshift=-0.65cm]Server}] (S6) {};

      % Cluster
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=6cm, minimum height=9.5cm,xshift=-3.5cm,yshift=3.4cm,label={[yshift=-0.65cm]HDFS Cluster}] (C1) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=6cm, minimum height=9.5cm,xshift=3.5cm,yshift=3.4cm,label={[yshift=-0.65cm]HDFS Cluster}] (C2) {};

      % Stuff
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.5cm,xshift=-2cm,yshift=9cm,label={[yshift=-0.5cm]Router}] (M1) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.5cm,xshift=2cm,yshift=9cm,label={[yshift=-0.5cm]Router}] (M2) {};
      \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.5cm,xshift=0cm,yshift=10cm,label={[yshift=-0.5cm]Router}] (M3) {};

      % Arrows
      \path (M3) edge (M1)
            (M3) edge (M2)
            (M1) edge (M3)
            (M2) edge (M3)
            (M1) edge (NN1)
            (NN1) edge (M1)
            (M2) edge (NN2)
            (NN2) edge (M2)
            (NN1) edge (DN1)
            (DN1) edge (NN1)
            ([xshift=0.5cm]NN1.south) edge ([xshift=0.5cm]DN2.north)
            ([xshift=0.5cm]DN2.north) edge ([xshift=0.5cm]NN1.south)
            (NN1) edge (DN5)
            (DN5) edge (NN1)
            ([xshift=-0.5cm]NN2.south) edge ([xshift=-0.5cm]DN3.north)
            ([xshift=-0.5cm]DN3.north) edge ([xshift=-0.5cm]NN2.south)
            (NN2) edge (DN4)
            (DN4) edge (NN2)
            (NN2) edge (DN6)
            (DN6) edge (NN2);
          \end{tikzpicture}
      }
      \caption{Hadoop cluster overview}\label{fig:hadoop}
\end{figure} 

\subsubsection{Apache Spark}\label{sec:spark}
Apache Spark is a general purpose cluster-computing system, that offers a high level programming API as well as a set of high-level tools, for SQL data, machine learning and graph processing~\cite{sparkintro}. The main advantage of Spark compared to the MapReduce offered by Hadoop is when working with iterative processes across the same data. Simply by keeping data cleverly in memory using Directed Acyclic Graphs, spark performs iterative processes much faster. An example iterative task is when computing the gradient for a logistic regression classification, the gradient for the separating hyperplane is found iteratively~\cite{ApacheSpark}.

A Spark application is a user-application that is run by the \emph{Driver Program}, the driver program handles the high-level control flow of an application and distributes various operations across the cluster. Spark comprises of two important abstractions for distributed parallel computation: \emph{resilient distributed datasets}(RDD) and \emph{parallel operations} on these datasets. Furthermore, Spark also supports two types of shared variables that can be used in functions running on the cluster.

The RDD is a read-only collection of objects which is distributed across the machines in the cluster. RDD's are similar to a list structure when working with them. RDDs can live both in-memory and on physical structure and are fault-tolerant in the sense that they can be rebuilt because they contain information about how they were built. The parallel operations which are incorporated into spark are: 
\begin{description}
  \item[Reduce:] Similar to the reduce action in MapReduce 
  \item[Collect:] All elements are sent to the driver program, as a list
  \item[Foreach:] Call a function on each element in the RDD
\end{description}
This is a sample spark application for counting words on a hadoop file system and output it into standard output.

\begin{lstlisting}
from pyspark import SparkContext
sc = SparkContext("spark://node1:7077")
text_file = sc.textFile("hdfs://node1:9000/dictionary.txt")
counts = text_file.flatMap(lambda line: line.split(" ")) \
                  .map(lambda word: (word, 1)) \
                  .reduceByKey(lambda a, b: a + b)
print counts.collect()
\end{lstlisting} 
The above code can be run by invoking pyspark, which is similar to the python interpreter. When invoked, the application is submitted to the spark running at \texttt{spark://node1:7077} through the sparkcontext. \texttt{text\_file} is an RDD with references to each line in the file on the HDFS. We then split each line on blank space, into arrays, which are flattened out by using flatmap. Each word is then sent a (key,value) pair and reduced by key, counting up the occurrences of the word. Lastly we use collect to print out words and their occurrences.


% \begin{figure}[!htb]
%   \centering
%   \scalebox{0.75}{
%     \begin{tikzpicture}[->,>=stealth',bend angle=45,auto]
%       % Tasks
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.8cm,xshift=0cm,yshift=0cm,label={[yshift=-0.65cm]Task}] (T1) {};
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.8cm,xshift=2cm,yshift=0cm,label={[yshift=-0.65cm]Task}] (T2) {};
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.8cm,xshift=0cm,yshift=4cm,label={[yshift=-0.65cm]Task}] (T3) {};
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.8cm,xshift=2cm,yshift=4cm,label={[yshift=-0.65cm]Task}] (T4) {};

%       % Caches
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.8cm,xshift=2cm,yshift=1cm,label={[yshift=-0.65cm]Cache}] (C1) {};
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=1.5cm, minimum height=0.8cm,xshift=2cm,yshift=5cm,label={[yshift=-0.65cm]Cache}] (C2) {};

%       % Executor
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=3.75cm, minimum height=2.15cm,xshift=1cm,yshift=0.5cm,label={[yshift=-0.85cm,xshift=-1cm]Executor}] (E1) {};
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=3.75cm, minimum height=2.15cm,xshift=1cm,yshift=4.5cm,label={[yshift=-0.85cm,xshift=-1cm]Executor}] (E2) {};

%       % Worker
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=3.95cm, minimum height=3cm,xshift=1cm,yshift=0.75cm,label={[yshift=-0.55cm,xshift=-0.8cm]Worker node}] (W1) {};
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=3.95cm, minimum height=3cm,xshift=1cm,yshift=4.75cm,label={[yshift=-0.55cm,xshift=-0.8cm]Worker node}] (W2) {};

%       % Cluster Manager
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=3.5cm, minimum height=2cm,xshift=-4cm,yshift=2.75cm,label={[yshift=-1.25cm]Cluster manager}] (CM) {};

%       % SparkContent
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=3.25cm, minimum height=1cm,xshift=-9cm,yshift=2.5cm,label={[yshift=-0.80cm]SparkContent}] (SC) {};

%       % Driver Program
%       \path node at (0,0) [draw,shape=rectangle, style=rounded corners, minimum width=3.5cm, minimum height=2cm,xshift=-9cm,yshift=2.75cm,label={[yshift=-0.65cm]Driver Program}] (DP) {};

%       % Edges
%       \path ([xshift=1cm]E1.north) edge ([xshift=1cm]E2.south)
%       ([xshift=1cm]E2.south) edge ([xshift=1cm]E1.north)
%       (CM) edge (W1)
%       (CM) edge (W2)
%       (W1) edge (CM)
%       (W2) edge (CM)
%       (SC) edge ([yshift=-0.25cm]CM.west)
%       ([yshift=-0.25cm]CM.west) edge (SC)
%       (SC.south east) edge [bend right] (E1.west)
%       (E2.west) edge [bend right] (SC.north east)
%       (SC.north east) edge [bend left] (E2.west)
%       (E1.west) edge [bend left] (SC.south east);

%     \end{tikzpicture}
%   }
%   \caption{Spark setup overview}\label{fig:spark}
% \end{figure} 

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../main"
%%% End:
