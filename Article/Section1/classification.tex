\section{Classification}\label{sec:classification}

% intro

% features - target(class)

\subsection{Linear Regression}
% linear regression
The goal of linear regression is to fit a linear function to a set of input-output pairs. 
If the input features are $X_1,X_2 \text{ ... } X_n$ and weights $\overline{w} = w_0, w_1 \text{ ... } w_n$.

$$f^{\overline{w}}(X_1,X_2, ... X_n) = w_0 + w_1 X_1 + w_2 X_2 + ... w_n X_n $$ 

We will learn the function for each target feature $Y$ seperately, so given a set $E$ of examples.
The function $val(e,X_i)$ give us the value of the feature $X_i$ in example $e \in E$. 

The function 
\begin{align}
pval(e,Y) &= w_0 + w_1 \text{ val}(e,X_1) + w_2 \text{ val}(e,X_2) + \text{ ... } w_n \text{ val}(e,X_n) \\
&= \sum^n_{i=0} w_i \text{ val}(e,X_i)
\end{align}

give us the predicted value for the target feature $Y$ for the training example $e$.
In order to avoid having a special case we assume a feature $X_0$ with $val(e,X_0)=1$.
\begin{flushright}
\cite[p. 304]{AI2010}
\end{flushright}


\subsection{Cost Function}
% cost function
A cost function is a measure on how much it will "cost" us if the prediction for a given example is wrong.

Three basic cost functions exist: the absolute error function, the sum-of-squares error function and 
the worst-case error function.
 
The absolute error function provides the sum of all absolute errors on the examples in $E$.

$$absErr = \sum_{e \in E}\sum_{Y \in T} |val(e,Y) - pval(e,Y)|$$

This function is allways non-negative and only zero when $Y$ is predicted correctly in all examples. 

The sum-of-squares error function assigns a larger error the further a prediction is from the actual value.

$$ssErr = \sum_{e \in E}\sum_{Y \in T} (val(e,Y) - pval(e,Y))^2$$

The worst-case error function gives the maximum error predicted for all examples.

$$maxErr = \max_{e \in E}\max_{Y \in T} | val(e,Y) - pval(e,Y) |$$

\begin{flushright}
\cite[p. 290-291]{AI2010}
\end{flushright}




\subsubsection{Regression with multiple variables}
% linear regression - multiple variables

\subsection{Logistic Regression}
% logistic function


\subsection{Regularization}
% regularization


\subsection{Large Datasets}
% Large datasets












